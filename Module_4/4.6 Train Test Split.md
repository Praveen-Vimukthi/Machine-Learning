# What is Trainâ€“Test Split?

Imagine this ğŸ‘‡

You are studying for an exam.

- You learn from a book â†’ this is training
- Then you take a test â†’ this is testing

In **Machine Learning**, it is the same idea.

ğŸ‘‰ We split the data into two parts:

- Training data â†’ to teach the model
- Testing data â†’ to check how well it learned

This is called Trainâ€“Test Split

--- 

## Why do we need Trainâ€“Test Split?

If you test the model using the same data it learned from, it may:

âŒ Memorize answers

âŒ Look very accurate

âŒ Fail on new (real) data

So we split the data to answer this question:

> â€œCan the model predict correctly on data it has never seen before?â€

---

## Simple Example

Suppose we have this dataset:

|**Hours Studied** | **Marks** |
| -------------- | ----- |
| 1             | 20    |
| 2             | 40    |
| 3             | 60    |
| 4             | 80    |
| 5             | 100   |

### Step 1: Split the data

Letâ€™s say:
- 80% â†’ Training
- 20% â†’ Testing

### Training data (used to learn):

| **Hours** | **Marks** |
| ----- | ----- |
| 1     | 20    |
| 2     | 40    |
| 3     | 60    |
| 4     | 80    |

### Testing data (used to test):

| **Hours** | **Marks** |
| ----- | ----- |
| 5     | 100   |

---

## What happens during training?

The model learns this pattern:

> â€œIf study hours increase, marks increase.â€

It learns using only training data.

---

## What happens during testing?

Now we ask the model:

> â€œIf a student studies 5 hours, what marks will they get?â€

- **Actual answer:** 100
- **Model prediction:** maybe 95 or 102

If prediction is close â†’ **good model**
If prediction is far â†’ **bad model**

---

## Common Split Ratios

These are very common:

| **Training** | **Testing**             |
| -------- | ------------------- |
| 70%      | 30%                 |
| 80%      | 20% âœ… (most common) |
| 90%      | 10%                 |

âœ” More training data = better learning

âœ” Enough testing data = fair evaluation

---

## Trainâ€“Test Split in Python (scikit-learn)

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# Create dataset
data = pd.DataFrame({
    'Hours_Studied': [1,2,3,4,5,6,7,8,9,10],
    'Result': ['Fail','Fail','Fail','Pass','Pass','Pass','Pass','Pass','Pass','Pass']
})

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42
)

print("Train Result     Count:")
print(y_train.value_counts())

print("\nTest Result    Count:")
print(y_test.value_counts())

```
**Output:**
```
Train Result    Count:
Pass              6
Fail              1

Test Result     Count:
Pass              1
Fail              2
```

### Meaning of Parameters

| **Parameter**      | **Meaning**                 |
| -------------- | ----------------------- |
| `X`            | Input features          |
| `y`            | Output labels           |
| `test_size`    | Percentage of test data |
| `random_state` | Fixes randomness        |

âš  Risk:

- One class may disappear in test data

---

## Trainâ€“Test Split WITH `stratify`

`stratify` keeps the SAME class proportion in both train and test data.

**In simple words:**

> â€œWhatever ratio exists in original data must also exist in train and test data.â€

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

print("Train Result Count:")
print(y_train.value_counts())

print("\nTest Result Count:")
print(y_test.value_counts())
```
**Output:**
```
Train Result     Count:
Pass                5
Fail                2

Test Result     Count:
Pass                2
Fail                1
```

### What Changed?

Original Dataset Ratio

- Pass = 7
- Fail = 3

      â¡ 70% Pass, 30% Fail

**After Stratified Split**

| **Dataset**  | **Pass** | **Fail** |
| -------- | ---- | ---- |
| Training | 5    | 2    |
| Testing  | 2    | 1    |

âœ… Same ratio preserved

âœ… Both classes appear everywhere

âœ… Fair model evaluation

### When should we use `stratify`?

| **Situation**              | **Use stratify?** |
| ---------------------- | ------------- |
| Classification problem | âœ… YES         |
| Imbalanced dataset     | âœ… YES         |
| Regression problem     | âŒ NO          |
| Continuous output      | âŒ NO          |

### Real-Life Example (Stratify)

Think of a school exam ğŸ“

- 90% students passed
- 10% students failed

If you test only passed students:

- You learn nothing about failures

`stratify` ensures:

- Passed & failed students appear in both training and testing

---

## Overfitting & Trainâ€“Test Split

| **Scenario                               | **Meaning**      |
| -------------------------------------- | ------------ |
| High train accuracy, low test accuracy | Overfitting  |
| Low train accuracy, low test accuracy  | Underfitting |
| High both                              | Good model   |

Trainâ€“Test Split helps detect overfitting.

---

## Final Summary

- Trainâ€“Test Split divides data into learning & checking

- Prevents memorization

- Shows real performance

- random_state â†’ reproducible results

- stratify â†’ keeps class balance

- Always use stratify for classification

- Most common split â†’ 80/20

---

## ğŸ—‚ Related Work Files

| Title                         | Link                                                 |
|------------------------------|------------------------------------------------------|
| ğŸ’» Google Colab File         | [View File](https://colab.research.google.com/drive/1HszwYF-0IxlTMpdMBg9l_KqEDO7a3XHK?authuser=2)               |


<table width="100%">
  <tr>
    <td align="left">
      <a href="https://github.com/Praveen-Vimukthi/Machine-Learning/blob/main/Module_4/4.5%20Label%20Encoding.md">&larr; Previous</a>
    </td>
    <td align="right">
      <a href="README_STEP3.md">Next &rarr;</a>
    </td>
  </tr>
</table>
