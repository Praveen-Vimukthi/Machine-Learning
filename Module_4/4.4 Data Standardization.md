# Standardization in Machine Learning

## ğŸ“Œ Overview

In Machine Learning, **data preprocessing** is crucial for model performance.  
**Feature Scaling** ensures numeric features are on a similar scale.  

This repository focuses on **Standardization**, a method to scale features.

---

## ğŸ“ What is Standardization?

Standardization rescales numeric features so they have:

- **Mean (Î¼) = 0**
- **Standard Deviation (Ïƒ) = 1**

It helps models converge faster and perform better when features have vastly different ranges.

Mathematically, it is represented by the **Z-Score formula:**: 

$$
Z = \frac{X - \mu}{\sigma}
$$

Where:

- \(X\) = original value  
- \(\mu\) = mean of dataset  
- \(\sigma\) = standard deviation  

**Key Points:**

- Values roughly lie between **-1 and 1**.  
- Maintains relative differences between values.  
- Improves training for models like **Gradient Descent-based models**.

---

## ğŸ“Š Example Dataset

```python
dataset_1 = [1, 99, 789, 5, 6859, 541, 94142, 7, 50826, 35464]
dataset_0 = [10, 5, 6, 1, 3, 7, 9, 4, 8, 2]  # x-axis
